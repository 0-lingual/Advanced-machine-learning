{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0-lingual/Advanced-machine-learning/blob/main/HW2_KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "\n",
        "\n",
        "# load MNIST data\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "\n",
        "# 60000 training dataset // 100000 training dataset\n",
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n"
      ],
      "metadata": {
        "id": "7gWzNvN6rCOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise: k-nearest neighbor (kNN) classifier with sklearn"
      ],
      "metadata": {
        "id": "Q_6gkvIoyt8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Xjimi8MAUp_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display Some of the (training) data\n",
        "sample_index = np.random.choice(60000, size=12)\n",
        "num_samples = sample_index.size\n",
        "\n",
        "random_samples = train_X[sample_index]\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "for k in range(num_samples):\n",
        "    plt.subplot(4, 4, k + 1)\n",
        "    plt.imshow(random_samples[k].reshape(28, 28),cmap='Greys')\n",
        "    plt.title(train_y[sample_index[k]])\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "86sYl3KEufy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare dataset for training (reshape)\n",
        "\n",
        "X_train = train_X.reshape(60000,784).astype(float)\n",
        "X_test = test_X.reshape(10000,784).astype(float)\n",
        "y_train = train_y\n",
        "y_test = test_y\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "u20wP3RurMek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# kNN with k=5 and L2 norm"
      ],
      "metadata": {
        "id": "3AHiK6TgzQWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# k-NN training with sklearn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "clf = KNeighborsClassifier(n_neighbors= 5, p = 2)      # 5-nearest neighbor // L2 norm\n",
        "clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "qLJUZIAnxhgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Measure the accuracy of the kNN\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "pred = clf.predict(X_test)\n",
        "print(\"Accuracy: \", accuracy_score(y_test, pred))\n"
      ],
      "metadata": {
        "id": "dmlN3rf8pHJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display test result (predicted labels and actual label)\n",
        "\n",
        "sample_index = np.random.choice(10000, size=12)     # take 12 random sample index\n",
        "num_samples = sample_index.size\n",
        "\n",
        "random_samples = test_X[sample_index]\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "for k in range(num_samples):\n",
        "    plt.subplot(4, 4, k + 1)\n",
        "    plt.imshow(random_samples[k].reshape(28, 28),cmap='Greys')\n",
        "    plt.title(\"True: \" + str( test_y[sample_index[k]]) + \", Pred: \" + str(pred[sample_index[k]]))\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wtN6AVAN3n7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Implement k-NN on your own (without sklearn)"
      ],
      "metadata": {
        "id": "nMq0vfRsxzkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# L2 distance\n",
        "def L2_distance(x, y):\n",
        "    return np.sqrt( np.sum((x - y)**2, axis=1) )\n"
      ],
      "metadata": {
        "id": "fS4n49dTpHf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your own K-nearest neighbor\n",
        "\n",
        "def my_kNN(X_train, y_train, X_test, k):\n",
        "    pred = []  # prediction result\n",
        "    for dat in X_test:\n",
        "######### Implement your codes here #########################\n",
        "        # measure distance between dat and training data\n",
        "        distance = L2_distance(X_train,dat)\n",
        "\n",
        "        # find k-minimum values (index)\n",
        "        k_indices = np.argsort(distance)[:k]\n",
        "        # take the majority vote\n",
        "        k_nearest_labels = y_train[k_indices]\n",
        "        majority_vote = np.bincount(k_nearest_labels).argmax()\n",
        "\n",
        "        pred.append(majority_vote)\n",
        "\n",
        "    return np.array(pred)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z1rJA7wGyAIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run your kNN classifier & measure accuracy\n",
        "\n",
        "# test your code with only 100 test data\n",
        "num_test = 100\n",
        "pred = my_kNN(X_train, y_train, X_test[:num_test], 5)\n",
        "print(\"Accuracy: \", accuracy_score(y_test[:num_test], pred))\n",
        "\n"
      ],
      "metadata": {
        "id": "3pX6Q0j61bSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display Some test results\n",
        "\n",
        "\n",
        "sample_index = np.random.choice(num_test, size=12)     # take 12 random sample index\n",
        "num_samples = sample_index.size\n",
        "\n",
        "random_samples = test_X[sample_index]\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "for k in range(num_samples):\n",
        "    plt.subplot(4, 4, k + 1)\n",
        "    plt.imshow(random_samples[k].reshape(28, 28),cmap='Greys')\n",
        "    plt.title(\"True: \" + str( test_y[sample_index[k]]) + \", Pred: \" + str(pred[sample_index[k]]))\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N2PmKUty66Wz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}